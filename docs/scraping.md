# Scraping-Leitfaden fÃ¼r das Vorlesungsverzeichnis

Dieser Leitfaden fasst erprobte Strategien zusammen, um den stateful Webauftritt [`https://evlvz.hrz.tu-freiberg.de/~vover/`](https://evlvz.hrz.tu-freiberg.de/~vover/) automatisiert auszulesen. Alle Beispiele verwenden `curl`; andere HTTP-Clients lassen sich analog einsetzen, solange sie Cookies Ã¼ber mehrere Requests hinweg beibehalten.

## 1. Sitzung aufbauen

Die Anwendung legt beim ersten Aufruf einen PHP-Session-Cookie (`PHPSESSID`) ab und hÃ¤ngt ihn sÃ¤mtlichen Folgeseiten an. Ohne diesen Cookie vergisst der Server u.â€¯a. die gewÃ¤hlte Semesterkonfiguration.

```bash
curl -c cookies.txt -b cookies.txt -L \
     https://evlvz.hrz.tu-freiberg.de/~vover/ \
     -o /tmp/start.html
```

Der kombinierte `-c/-b`-Einsatz speichert und sendet die Session automatisch weiter. Skripte sollten deshalb konsequent mit einer gemeinsamen Cookie-Datei arbeiten.

## 2. Semester wÃ¤hlen

Die Startseite enthÃ¤lt ein `select`-Feld `sem_wahl` und ein verstecktes Feld `wechsel`. Ein POST auf `index.html` speichert das gewÃ¼nschte Semester serverseitig in der Session.

```bash
curl -s -c cookies.txt -b cookies.txt \
     -d "sem_wahl=Sommersemester+2024&wechsel=4" \
     https://evlvz.hrz.tu-freiberg.de/~vover/index.html
```

* `sem_wahl` akzeptiert den sichtbaren Text (z.â€¯B. `Wintersemester 2025 / 2026`).
* `wechsel=3` (JavaScript-Auto-Submit) oder `wechsel=4` (Noscript-Variante) funktionieren beide.

Die Auswahl lÃ¤sst sich mit einem nachfolgenden GET verifizieren â€“ im HTML trÃ¤gt die entsprechende `option` das Attribut `selected`.

## 3. Suchformular verstehen

Die Seite [`suche.html`](https://evlvz.hrz.tu-freiberg.de/~vover/suche.html) liefert sÃ¤mtliche Auswahllisten (RÃ¤ume, Wochentage, HÃ¶rergruppen, Semester etc.). Wichtige Details:

* Jedes Kriterium wird durch ein Checkbox-Feld `suche[XYZx]` aktiviert.
* Der eigentliche Wert steckt in `suche[XYZ]`.
* Die Senden-SchaltflÃ¤che trÃ¤gt den Namen `senden` und den Wert `  Suchen  ` (mit fÃ¼hrenden und abschlieÃŸenden Leerzeichen). Serverseitig genÃ¼gt allerdings auch `senden=Suchen`.

Beim automatisierten AusfÃ¼llen mÃ¼ssen **Checkbox und Feld** Ã¼bertragen werden, sonst lehnt der Server die Anfrage mit â€WÃ¤hlen Sie bitte ein Suchkriterium aus!â€œ ab.

Beispiel: Volltextsuche nach Veranstaltungen, deren Titel â€Mathematikâ€œ enthÃ¤lt.

```bash
curl -s -c cookies.txt -b cookies.txt \
     -d "suche%5Btitelx%5D=1&suche%5Btitel%5D=Mathematik&senden=Suchen" \
     https://evlvz.hrz.tu-freiberg.de/~vover/ergebnis.html \
     -o /tmp/ergebnis.html
```

## 4. Suchergebnisse verarbeiten

Die Antwortseite `ergebnis.html` enthÃ¤lt eine Tabelle mit allen Treffern. Pro Zeile tauchen u.â€¯a. folgende Elemente auf:

* `input type="checkbox" name="check[]" value="<ID>` â€“ die ID identifiziert die Lehrveranstaltung eindeutig.
* Spalten `Art`, `Titel`, `Lehrende`, `Tag`, `Zeit`, `Raum`, `Woche` und eine Info-SchaltflÃ¤che.
* Die Info-SchaltflÃ¤che ruft `javascript:info_lv_fenster(<ID>)` auf; ohne JavaScript fÃ¼hrt der `<noscript>`-Link direkt zu `info.html?satz=<ID>`.

Die relevanten Lehrveranstaltungsnummern kÃ¶nnen fÃ¼r Detailabfragen oder spÃ¤tere Sammelaktionen weiterverwendet werden. Zum Parsen bieten sich HTML-Parser an, die Tabellenstrukturen robust verarbeiten kÃ¶nnen.

## 5. Detailinformationen abrufen

FÃ¼r jede ID liefert [`info.html?satz=<ID>`](https://evlvz.hrz.tu-freiberg.de/~vover/info.html?satz=16009) eine eigenstÃ¤ndige Seite mit:

* Veranstaltungstitel, Typ und Lehrende
* TerminblÃ¶cken (Tag, Uhrzeit, Raum, Turnus)
* Auflistung der zugehÃ¶rigen HÃ¶rergruppen inkl. Status (Pflicht/Wahlpflicht/etc.)

Die Seite benÃ¶tigt lediglich die aktive Session; weitere Parameter sind nicht nÃ¶tig.

## 6. RaumplÃ¤ne exportieren

Die Seite [`plaene.html`](https://evlvz.hrz.tu-freiberg.de/~vover/plaene.html) enthÃ¤lt ein `select`-Feld `raum` und zwei Buttons:

* `html_send=Raumplan als HTML`
* `pdf_send=Raumplan als PDF`

Beim HTML-Export fÃ¼hrt der Server zuerst `raumplan.html`, welche einen Meta-Refresh auf `druck_html.html?art=raumplan&raum=<...>` auslÃ¶st. Der finale Inhalt (WochenÃ¼bersicht mit Verlinkung auf `info.html?satz=...`) steckt in `druck_html.html`.

```bash
curl -s -b cookies.txt \
     "https://evlvz.hrz.tu-freiberg.de/~vover/druck_html.html?art=raumplan&raum=PR%C3%9C-1103" \
     -o /tmp/raumplan.html
```

FÃ¼r den PDF-Export kann man stattdessen `raumplan.html?raum=...&pdf_send=Raumplan+als+PDF` aufrufen und dem `Location`-/Meta-Refresh folgen; der Server liefert ein binÃ¤res PDF.

## 7. StudiengangsplÃ¤ne Ã¼ber `stgvrz.html`

Die Navigation â€PlÃ¤ne nach Studiengangâ€œ verlinkt direkt auf `stgvrz.html`. Praktisch wichtige Punkte:

* Die Linkliste (z.â€¯B. aus `verz.html`) enthÃ¤lt Kennungen wie `stdg=BAI` und den Klartextnamen `stdg1=Angewandte Informatik (Bachelor)`. Die Paare lassen sich aus dem HTML auslesen, indem alle Links auf `stgvrz.html?stdg=` gesammelt und ihre Parameter ausgewertet werden.
* Der eigentliche Stundenplan steckt in einer Tabelle innerhalb von `stgvrz.html`. Der gewÃ¼nschte Fachsemester-Filter (`semest`) wird per POST gesetzt.

```bash
curl -s -c cookies.txt -b cookies.txt \
     -d "stdg=BAI&stdg1=Angewandte+Informatik+(Bachelor)&semest=4.Semester" \
     https://evlvz.hrz.tu-freiberg.de/~vover/stgvrz.html \
     -o /tmp/studiengang-plan.html
```

Die Tabelle besitzt eine konsistente Struktur (Spalten â€Artâ€œ, â€Titelâ€œ, â€Lehrendeâ€œ, â€Tagâ€œ, â€Zeitâ€œ, â€Raumâ€œ, â€Wocheâ€œ, â€Infoâ€œ) und lÃ¤sst sich analog zu den Suchergebnissen auswerten. FÃ¼r mehrere Fachsemester einfach Werte wie `2.Semester`, `4.Semester`, `6.Semester`, â€¦ iterieren.

Unterhalb der Tabelle verlinkt der Server zusÃ¤tzliche Exporte:

* `druck_html.html?art=stundenplan&gang=<NAME>%23false%23<SEM>` liefert eine reduzierte HTML-Ansicht.
* `druck_pdf.html?â€¦` und `druck_txt.html?â€¦` geben jeweils PDF-Dateien zurÃ¼ck (trotz der Dateiendung â€txtâ€œ).

Diese URLs benÃ¶tigen dieselbe Session (wegen Semesterkontext) und dieselben Parameter wie `stgvrz.html`.

## 8. Weitere Endpunkte

* `samml.html` / `stundenplan.html` akzeptieren GET-Requests mit denselben `check[]`-IDs wie aus den Suchtabellen. Das MenÃ¼ lÃ¶st diese Aufrufe sonst via JavaScript (`funct.js`) aus.
* `druck_html.html` unterstÃ¼tzt weitere `art`-Parameter (z.â€¯B. `sammlung`, `stundenplan`) und erzeugt druckfertige HTML-Ausgaben.
* Die Anwendung liefert konsequent UTF-8 kodierte Seiten; Sonderzeichen wie `Ãœ` mÃ¼ssen bei GET-Parametern URL-kodiert werden (`PR%C3%9C-1103`).

## 9. Empfehlungen fÃ¼r produktives Scraping

1. **Session-Reuse:** Verwende eine persistente Cookie-Datei, damit alle Navigationsschritte dasselbe `PHPSESSID` nutzen.
2. **Formulare frisch auslesen:** Die Optionslisten (RÃ¤ume, HÃ¶rergruppen usw.) Ã¤ndern sich pro Semester. Hole `suche.html`, `plaene.html` oder `verz.html` regelmÃ¤ÃŸig, anstatt Werte hart zu codieren.
3. **JavaScript-Fallbacks nutzen:** Fast alle Aktionen bieten `<noscript>`-Links. Diese zeigen exakt die URLs an, die man automatisiert ansteuern kann.
4. **Redirects verfolgen:** Einige Exporte (Raumplan, Stundenplan) arbeiten mit Meta-Refresh. Folge daher automatisch auf `druck_html.html` oder werte das `meta http-equiv="refresh"`-Tag aus.
5. **Respectful Crawling:** Begrenze Request-Raten, da jede Aktion serverseitig Datenbankarbeit auslÃ¶st und der Dienst Ã¶ffentlich fÃ¼r Studierende bereitsteht.
6. **Antworten prÃ¼fen:** Ãœberwache Statuscodes und AntwortgrÃ¶ÃŸen, um Session-Timeouts oder Fehlermeldungen frÃ¼h zu erkennen.

---

## 10. Aktuelle Implementierung im TUBAF Planner

Der **TUBAF Planner** implementiert ein robustes Scraping-System basierend auf den oben beschriebenen Strategien. Die Implementierung nutzt **OkHttp3** als HTTP-Client und **JSoup** zum HTML-Parsing.

### 10.1 Architektur

```
TubafScrapingService
â”œâ”€â”€ TubafScraperSession (Session-Management)
â”‚   â”œâ”€â”€ Cookie-Handling (JavaNetCookieJar + CookieManager)
â”‚   â”œâ”€â”€ fetchSemesterOptions() â†’ Liest select[name=sem_wahl]
â”‚   â”œâ”€â”€ selectSemester() â†’ POST mit sem_wahl + wechsel=4
â”‚   â”œâ”€â”€ fetchStudyPrograms() â†’ Parst verz.html fÃ¼r StudiengÃ¤nge
â”‚   â”œâ”€â”€ openProgram() â†’ GET stgvrz.html?stdg=...
â”‚   â””â”€â”€ openProgramSemester() â†’ POST mit stdg, stdg1, semest
â”œâ”€â”€ Discovery Mode â†’ Findet automatisch alle verfÃ¼gbaren Semester
â”œâ”€â”€ Remote Scraping â†’ Scrapt ausgewÃ¤hlte Remote-Semester
â””â”€â”€ Local Scraping â†’ Scrapt bereits erstellte lokale Semester
```

### 10.2 Implementierte Features

#### âœ… **Session-Management (Punkt 1)**
- Persistente Cookie-Verwaltung Ã¼ber `JavaNetCookieJar`
- `CookiePolicy.ACCEPT_ALL` fÃ¼r alle TUBAF-Cookies
- Automatisches Session-Reuse Ã¼ber alle Requests hinweg

```kotlin
private val cookieManager = CookieManager().apply {
    setCookiePolicy(CookiePolicy.ACCEPT_ALL)
}
private val httpClient = OkHttpClient.Builder()
    .cookieJar(JavaNetCookieJar(cookieManager))
    .build()
```

#### âœ… **Semester-Auswahl (Punkt 2)**
- `fetchSemesterOptions()` extrahiert alle verfÃ¼gbaren Semester aus `select[name=sem_wahl]`
- `selectSemester()` sendet POST mit korrekten Parametern (`sem_wahl`, `wechsel=4`)
- Semester-Matching unterstÃ¼tzt verschiedene Namensformate

#### âœ… **StudiengangsplÃ¤ne (Punkt 7)**
- `fetchStudyPrograms()` parst `verz.html` und extrahiert:
  - Studiengangscodes (`stdg`)
  - Klartextnamen (`stdg1`)
  - FakultÃ¤tszuordnung
  - Links zu `stgvrz.html`
- `openProgramSemester()` scrapt Fachsemester-spezifische PlÃ¤ne
- Tabellen werden robust mit JSoup geparst (Spalten: Art, Titel, Lehrende, Tag, Zeit, Raum, Woche)

#### âœ… **Intelligentes Entity-Management**
- **Dozenten**: Automatische Erkennung und Wiederverwendung basierend auf Name + Titel
- **RÃ¤ume**: Parsing von "GebÃ¤ude/Raum"-Format (z.B. "PRÃœ-1103")
- **Kurse**: Deduplizierung nach Name + Semester
- **Veranstaltungstypen**: Dynamische Erstellung (V, Ãœ, P, S, etc.)

#### âœ… **Change Tracking**
- Jeder Scraping-Lauf wird protokolliert (`ScrapingRun`)
- Ã„nderungen an EntitÃ¤ten werden getrackt (`ChangeLog`)
- Statistiken: Anzahl neuer/aktualisierter EintrÃ¤ge pro Run

#### âœ… **Progress Tracking**
- Echtzeit-Fortschrittsanzeige wÃ¤hrend des Scrapings
- Detaillierte Logs mit Emoji-Indikatoren fÃ¼r bessere Lesbarkeit
- Job-Management mit Abbruch-FunktionalitÃ¤t

### 10.3 NICHT implementierte Features

Diese Features aus der Dokumentation wurden bewusst **nicht** implementiert, da sie fÃ¼r den aktuellen Anwendungsfall nicht benÃ¶tigt werden:

#### âŒ **Suchformular (Punkt 3-4)**
- `suche.html` mit Checkbox-Feldern `suche[XYZx]`
- `ergebnis.html` mit Suchergebnissen
- **Grund**: Wir scrapen direkt Ã¼ber StudiengangsplÃ¤ne, was vollstÃ¤ndigere Daten liefert

#### âŒ **Detailinformationen (Punkt 5)**
- `info.html?satz=<ID>` fÃ¼r Veranstaltungsdetails
- **Potenzial**: KÃ¶nnte fÃ¼r zusÃ¤tzliche Infos (HÃ¶rergruppen, Turnus-Details) nÃ¼tzlich sein
- **Status**: Optional fÃ¼r zukÃ¼nftige Erweiterung

#### âŒ **RaumplÃ¤ne (Punkt 6)**
- `plaene.html` und `druck_html.html?art=raumplan`
- **Potenzial**: Feature-Request fÃ¼r Raumverwaltung
- **Status**: Nicht prioritÃ¤r, da Rauminformationen bereits aus StudiengangsplÃ¤nen extrahiert werden

#### âŒ **Weitere Endpunkte (Punkt 8)**
- `samml.html`, `stundenplan.html`, `druck_pdf.html`
- **Grund**: Unsere HTML-Parsing-Strategie ist bereits ausreichend

### 10.4 API-Endpunkte

Das Scraping-System bietet folgende REST-Endpunkte:

```
POST /api/scraping/discover-and-scrape
  â†’ Findet automatisch alle verfÃ¼gbaren Semester und scrapt sie

POST /api/scraping/scrape-remote
  â†’ Scrapt ausgewÃ¤hlte Remote-Semester
  Body: { "semesterIdentifiers": ["Sommersemester 2024", ...] }

POST /api/scraping/semester/{semesterId}/scrape
  â†’ Scrapt ein bereits erstelltes lokales Semester

GET /api/scraping/status
  â†’ Gibt aktuellen Scraping-Status zurÃ¼ck (lÃ¤uft/idle)

POST /api/scraping/cancel
  â†’ Bricht laufendes Scraping ab
```

### 10.5 Logging & Monitoring

Das System nutzt **umfangreiches Emoji-basiertes Logging** fÃ¼r bessere Ãœbersicht:

```
ğŸš€ Starting TUBAF scraping...
ğŸ”§ Initializing browser...
ğŸ“š Processing study program [1/25]: BAI
ğŸ‘¨â€ğŸ« Creating new lecturer: 'Prof. Dr. MÃ¼ller'
ğŸ« Using existing room: 'PRÃœ-1103' (ID: 42)
ğŸ“š Creating new course: 'Mathematik I' for semester 'WS24'
âœ… Schedule entry created for course 'Mathematik I' at 'Mo 08:00-09:30'
ğŸ‰ FINAL RESULT: Scraping completed successfully!
```

### 10.6 Best Practices (implementiert)

1. âœ… **Session-Reuse**: Alle Requests nutzen dieselbe Session mit persistenten Cookies
2. âœ… **Dynamische Formulardaten**: Semester-Optionen werden zur Laufzeit ausgelesen
3. âœ… **Referer-Header**: Korrekte Referer fÃ¼r alle POST-Requests
4. âœ… **UTF-8 Encoding**: Sonderzeichen werden korrekt verarbeitet
5. âœ… **Error Handling**: Detaillierte Fehlerbehandlung mit Retry-Logik
6. âœ… **Transaction Management**: Spring `@Transactional` fÃ¼r Datenkonsistenz
7. âœ… **Background Jobs**: Asynchrones Scraping mit Job-Management

### 10.7 ErweiterungsmÃ¶glichkeiten

Folgende Features kÃ¶nnten in Zukunft implementiert werden:

1. **Detailinformationen via `info.html`**: ZusÃ¤tzliche Veranstaltungsdetails (HÃ¶rergruppen, genauer Turnus)
2. **Raumplan-Integration**: Scraping von `plaene.html` fÃ¼r Raumverwaltung
3. **PDF-Export**: Nutzung von `druck_pdf.html` fÃ¼r Exportfunktionen
4. **Suchfunktion**: Integration von `suche.html` fÃ¼r gezielte Abfragen
5. **Incremental Updates**: Nur geÃ¤nderte Daten scrapen statt kompletter Refresh

---